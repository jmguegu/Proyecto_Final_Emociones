{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "552JAm2XynHk"
      },
      "source": [
        "# Recopilación de datos para la muestra\n",
        "\n",
        "En esta sección se generará una muestra de datos sintéticos, según los parámetros obtenidos del Instituto Nacional de Estadística (INE) de España.\n",
        "\n",
        "Los datos recogen estadísticas sobre la siguiente información por comunidad autónoma:\n",
        "\n",
        "* Población\n",
        "* Edades\n",
        "* Género\n",
        "* Actividad física\n",
        "* Asistencia a eventos (cine, deportivos, en directo, culturales)\n",
        "* Calidad del aire (días de alta contaminación, PM10)\n",
        "* Criminalidad\n",
        "* Nivel educativo\n",
        "* Estado civil\n",
        "* Horas trabajadas al mes\n",
        "* Salario bruto anual\n",
        "* Satisfacción sanitaria"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c54W174ty9ZZ"
      },
      "source": [
        "## Configuración básica\n",
        "\n",
        "Importación de librerías necesarias, y otras configuraciones para el correcto funcionamiento de los scripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFtYokm189Vh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=UserWarning)\n",
        "warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)\n",
        "\n",
        "# Establecemos una semilla para reducir la aleatoriedad de los datos\n",
        "np.random.seed(123)\n",
        "random.seed(123)\n",
        "\n",
        "data_basepath = '..\\\\data\\\\spain_original_data\\\\'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMITQ-3OzIzk"
      },
      "source": [
        "## Funciones\n",
        "\n",
        "Funciones necesarias para la generacion de datos a partir de las estadísticas del INE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLUKFfCy9fTp"
      },
      "outputs": [],
      "source": [
        "# Generador inicial del dataframe de muestra\n",
        "def initial_dataframe_generator(values, weights, size):\n",
        "  \"\"\"\n",
        "  Genera un DataFrame de pandas con una única columna de valores muestreados\n",
        "  de una lista con probabilidades (pesos) dados.\n",
        "\n",
        "  Args:\n",
        "    values (list): La lista de valores de los que se muestreará.\n",
        "    weights (list): La lista de pesos (probabilidades) correspondientes a cada valor.\n",
        "                  Debe tener la misma longitud que 'valores'. Si la suma es mayor a 1\n",
        "                  los valores serán normalizados.\n",
        "    size (int): El número de filas en el DataFrame generado.\n",
        "\n",
        "  Returns:\n",
        "    pd.DataFrame: Un DataFrame de pandas con una columna llamada 'Valor_Aleatorio'\n",
        "                  que contiene los valores muestreados según los pesos.\n",
        "  \"\"\"\n",
        "  if len(values) != len(weights):\n",
        "    raise ValueError(\"Las listas de valores y pesos deben tener la misma longitud.\")\n",
        "\n",
        "  # Asegurarse de que los pesos suman 1, si no, normalizarlos\n",
        "  weights_num = sum(weights)\n",
        "  probability = [p / weights_num for p in weights]\n",
        "\n",
        "  # Generar los valores aleatorios usando np.random.choice\n",
        "  random_values = np.random.choice(values, size=size, p=probability)\n",
        "\n",
        "  # Crear el DataFrame\n",
        "  df_generado = pd.DataFrame({'comunidad_autonoma': random_values})\n",
        "\n",
        "  return df_generado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P75hw0TJGpO6"
      },
      "outputs": [],
      "source": [
        "# Función encargada de elegir un valor aleatorio de entre una lista, con una probabilidad dada\n",
        "def generate_categorical_column(df, column_name, values_list, values_weights):\n",
        "  \"\"\"\n",
        "  Incluye una columna en un DataFrame con valores aleatorios de una lista,\n",
        "  siguiendo una distribución de pesos dada.\n",
        "\n",
        "  Args:\n",
        "    df (pd.DataFrame): El DataFrame al que se añadirá la columna.\n",
        "    column_name (str): El nombre de la nueva columna.\n",
        "    values_list (list): La lista de posibles valores para la nueva columna.\n",
        "    values_weights (list): La lista de pesos (probabilidades) correspondientes a\n",
        "                           cada valor en 'values_list'. Debe tener la misma\n",
        "                           longitud que 'values_list'.\n",
        "\n",
        "  Returns:\n",
        "    pd.DataFrame: El DataFrame original con la nueva columna añadida.\n",
        "                  Retorna el DataFrame original si hay un error en los pesos.\n",
        "  \"\"\"\n",
        "  if len(values_list) != len(values_weights):\n",
        "    print(\"Error: Las listas de valores y pesos deben tener la misma longitud.\")\n",
        "    return df\n",
        "\n",
        "  # Normalizar los pesos para que sumen 1 y puedan usarse como probabilidades\n",
        "  total_weights = sum(values_weights)\n",
        "  if total_weights == 0:\n",
        "      print(\"Error: La suma de los pesos es cero.\")\n",
        "      return df\n",
        "  probabilities = [w / total_weights for w in values_weights]\n",
        "\n",
        "  # Generar los valores aleatorios para la nueva columna\n",
        "  # El tamaño debe ser igual al número de filas del DataFrame\n",
        "  num_rows = len(df)\n",
        "  random_values = random.choices(values_list, weights=probabilities, k=num_rows)\n",
        "\n",
        "  # Añadir la nueva columna al DataFrame\n",
        "  df[column_name] = random_values\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNJyoaoQD23r"
      },
      "outputs": [],
      "source": [
        "# Generación de columnas categóricas en función de los pesos por comunidad autónoma\n",
        "def include_categorical_values(df_to_include, df_weights, weight_columns, new_column_name, value_column=\"comunidad_autonoma\"):\n",
        "    \"\"\"\n",
        "    Aplica la función generate_categorical_column a un DataFrame por cada comunidad\n",
        "    autónoma, usando los pesos de otro DataFrame de valores.\n",
        "\n",
        "    Args:\n",
        "      df_to_include (pd.DataFrame): El DataFrame al que se le añadirá la nueva columna.\n",
        "                                   Debe contener una columna 'comunidad_autonoma'.\n",
        "      df_weights (pd.DataFrame): El DataFrame que contiene los valores y pesos\n",
        "                                por comunidad autónoma. Debe contener la columna\n",
        "                                especificada en 'value_column' y las columnas\n",
        "                                especificadas en 'weight_columns'.\n",
        "      weight_columns (list): Una lista de nombres de columnas en df_weights que\n",
        "                             contienen los pesos para cada categoría. Estos nombres\n",
        "                             serán los valores posibles para la nueva columna.\n",
        "      new_column_name (str): El nombre de la nueva columna que se añadirá a df_to_include.\n",
        "      value_column (str): El nombre de la columna en df_weights que identifica la comunidad\n",
        "                          autónoma (ej. 'comunidad_autonoma').\n",
        "\n",
        "    Returns:\n",
        "      pd.DataFrame: El DataFrame original (df_to_include) con la nueva columna añadida.\n",
        "                    Retorna el DataFrame original si hay errores.\n",
        "    \"\"\"\n",
        "    if value_column not in df_weights.columns:\n",
        "        print(f\"Error: La columna '{value_column}' no se encuentra en df_weights.\")\n",
        "        return df_to_include\n",
        "\n",
        "    if not all(col in df_weights.columns for col in weight_columns):\n",
        "        missing_cols = [col for col in weight_columns if col not in df_weights.columns]\n",
        "        print(f\"Error: Faltan las siguientes columnas de peso en df_weights: {missing_cols}\")\n",
        "        return df_to_include\n",
        "\n",
        "    if 'comunidad_autonoma' not in df_to_include.columns:\n",
        "         print(f\"Error: El DataFrame a incluir no tiene la columna 'comunidad_autonoma'.\")\n",
        "         return df_to_include\n",
        "\n",
        "    # Crear una copia del DataFrame original para evitar SettingWithCopyWarning\n",
        "    df_result = df_to_include.copy()\n",
        "\n",
        "    # Lista para almacenar los DataFrames procesados por comunidad\n",
        "    processed_dfs = []\n",
        "\n",
        "    # Iterar sobre cada comunidad única en el DataFrame a incluir\n",
        "    for comunidad in df_result['comunidad_autonoma'].unique():\n",
        "        # Filtrar el DataFrame de valores para la comunidad actual\n",
        "        comunidad_values = df_weights[df_weights[value_column] == comunidad]\n",
        "\n",
        "        if comunidad_values.empty:\n",
        "            print(f\"Advertencia: No se encontraron datos de valores para la comunidad '{comunidad}'. Saltando.\")\n",
        "            # Añadir filas de la comunidad sin la nueva columna (se puede añadir un valor por defecto si es necesario)\n",
        "            processed_dfs.append(df_result[df_result['comunidad_autonoma'] == comunidad])\n",
        "            continue\n",
        "\n",
        "        # Extraer los pesos para la comunidad actual\n",
        "        # .iloc[0] para obtener la primera (y única) fila después del filtro\n",
        "        weights_list = comunidad_values.loc[:, weight_columns].iloc[0].tolist()\n",
        "\n",
        "        # Filtrar el DataFrame a incluir para la comunidad actual\n",
        "        df_comunidad = df_result[df_result['comunidad_autonoma'] == comunidad]\n",
        "\n",
        "        # Aplicar la función generate_categorical_column a la sub-DataFrame de la comunidad\n",
        "        # Pasamos los nombres de las columnas de pesos como los valores posibles\n",
        "        df_comunidad_processed = generate_categorical_column(\n",
        "            df_comunidad,\n",
        "            new_column_name,\n",
        "            weight_columns,  # Los nombres de las columnas de peso son los valores\n",
        "            weights_list     # Los valores dentro de esas columnas son los pesos\n",
        "        )\n",
        "\n",
        "        # Añadir el DataFrame procesado a la lista\n",
        "        processed_dfs.append(df_comunidad_processed)\n",
        "\n",
        "    # Concatenar todos los DataFrames procesados\n",
        "    if processed_dfs:\n",
        "        df_final = pd.concat(processed_dfs, ignore_index=True)\n",
        "        return df_final\n",
        "    else:\n",
        "        print(\"No se procesó ninguna comunidad.\")\n",
        "        return df_to_include # Retorna el original si no se pudo procesar nada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpW6BCHus_2j"
      },
      "outputs": [],
      "source": [
        "# Generación de datos numéricos en función de las medias por comunidad autónoma\n",
        "def generate_numerical_column(df, df_means, new_col_name, mean_col_in_means_df, ca_col='comunidad_autonoma', std_dev=None):\n",
        "    \"\"\"\n",
        "    Añade una columna con valores aleatorios con distribución normal a un DataFrame.\n",
        "\n",
        "    Los valores se generan para cada fila basándose en la media correspondiente\n",
        "    a la 'Comunidad_Autonoma' de esa fila, obtenida de otro DataFrame.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame original con la columna 'ca_col'.\n",
        "        df_means (pd.DataFrame): DataFrame que contiene las medias por 'ca_col'\n",
        "                                  en la columna 'mean_col_in_means_df'.\n",
        "        new_col_name (str): Nombre para la nueva columna a añadir en `df`.\n",
        "        mean_col_in_means_df (str): Nombre de la columna en `df_means` que contiene\n",
        "                                    los valores medios para cada comunidad.\n",
        "        ca_col (str): Nombre de la columna que identifica la comunidad autónoma\n",
        "                      en ambos DataFrames.\n",
        "        std_dev (float): Desviación estándar para la distribución normal. Si no se\n",
        "                         especifica, se usará el 25% la media global de los datos.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: El DataFrame original con la nueva columna añadida.\n",
        "    \"\"\"\n",
        "    # Crear un diccionario de mapeo de Comunidad Autónoma a su media\n",
        "    mean_map = df_means.set_index(ca_col)[mean_col_in_means_df].to_dict()\n",
        "\n",
        "    if std_dev == None:\n",
        "        std_dev = df_means[mean_col_in_means_df].mean() / 4\n",
        "\n",
        "    # Función para aplicar a cada fila y generar el valor aleatorio\n",
        "    def generate_random_value(row):\n",
        "        ca = row[ca_col]\n",
        "        # Obtener la media para la CA de la fila, si no existe, usar una media por defecto\n",
        "        mean = mean_map.get(ca, df_means[mean_col_in_means_df].mean()) # Usar media global si no se encuentra la CA\n",
        "\n",
        "        # Generar un valor aleatorio con distribución normal\n",
        "        random_value = np.random.normal(mean, std_dev)\n",
        "\n",
        "        # Asegurar que el valor sea positivo\n",
        "        return max(0, round(random_value, 4))\n",
        "\n",
        "    # Aplicar la función a cada fila para crear la nueva columna\n",
        "    df[new_col_name] = df.apply(generate_random_value, axis=1)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H20MVyxRzS-1"
      },
      "source": [
        "## Generación de la muestra\n",
        "\n",
        "Es necesario crear una muestra inicial, proporcional a la población de cada Comunidad Autónoma, a la que posteriormente se irá añadiendo información de cada una de las estadísticas obtenidas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Porb1ZnVHLcj"
      },
      "outputs": [],
      "source": [
        "# GENERACIÓN DE MUESTRA DE POBLACIÓN\n",
        "# Lista de posibles valores para comunidades autónomas\n",
        "comunidades = [\"Andalucía\",\"Aragón\",\"Asturias. Principado de\",\"Balears. Illes\",\n",
        "               \"Canarias\",\"Cantabria\",\"Castilla y León\",\"Castilla - La Mancha\",\n",
        "               \"Cataluña\",\"Comunitat Valenciana\",\"Extremadura\",\"Galicia\",\n",
        "               \"Madrid. Comunidad de\",\"Murcia. Región de\",\"Navarra. Comunidad Foral de\",\"País Vasco\",\n",
        "               \"Rioja. La\",\"Ceuta\",\"Melilla\"]\n",
        "\n",
        "# Pesos poblacionales ordenados correspondientes a cada comunidad\n",
        "poblacion = [8472407,1326261,1011792,1173008,\n",
        "             2172944,584507,2383139,2049562,\n",
        "             7763362,5058138,1059501,2695645,\n",
        "             6751251,1518486,661537,2213993,\n",
        "             319796,83517,86261]\n",
        "\n",
        "# Tamaño de la poblacion de muestra\n",
        "DF_SIZE = 2000\n",
        "\n",
        "# Generar el DataFrame\n",
        "df_muestra = initial_dataframe_generator(comunidades, poblacion, DF_SIZE)\n",
        "\n",
        "df_muestra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rm3jQy79Jy5S"
      },
      "source": [
        "## Inclusión de columnas\n",
        "\n",
        "Se irán incluyendo las columnas correspondientes a los datos procedentes del INE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2M5hhRBKMyt"
      },
      "source": [
        "### Edades de la población\n",
        "\n",
        "Las edades de la población se establecen por rangos de 5 años, según `edades_por_comunidad.csv`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdVOGetiKBTo"
      },
      "outputs": [],
      "source": [
        "# Leer el fichero con los datos de las edades\n",
        "df_ages = pd.read_csv(f'{data_basepath}edades_por_comunidad.csv', delimiter=\";\")\n",
        "df_ages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ammOXz8yLaly"
      },
      "outputs": [],
      "source": [
        "# Columnas con los pesos\n",
        "ages_weight_columns = [col for col in df_ages.columns if col != 'comunidad_autonoma']\n",
        "\n",
        "# Obviamos los datos de la población menores de 10 años para este esudio\n",
        "ages_weight_columns.remove(\"0-4_anos\")\n",
        "ages_weight_columns.remove(\"5-9_anos\")\n",
        "ages_weight_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAAUl4GmL5VP"
      },
      "outputs": [],
      "source": [
        "# Generamos la columna categórica \"rango_edad\" con los valores de \"df_ages\" como pesos\n",
        "df_muestra = include_categorical_values(df_muestra, df_ages, ages_weight_columns, \"rango_edad\")\n",
        "df_muestra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Establecemos un valor numérico para los rangos de edad\n",
        "def set_random_age_in_range(rango_str):\n",
        "  # Rango de edad X-Y_anos\n",
        "  age_range = rango_str.replace('_anos', '').split('-')\n",
        "  min_age = int(age_range[0])\n",
        "  max_age = int(age_range[1])\n",
        "  return random.randint(min_age, max_age)\n",
        "  \n",
        "# Aplicar la función a la columna 'rango_edad' para crear la nueva columna 'edad' con un dato numérico\n",
        "df_muestra['edad'] = df_muestra['rango_edad'].apply(set_random_age_in_range)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Eliminamos la columna 'rango_edad' ya que no es necesaria\n",
        "df_muestra.drop(columns=['rango_edad'], inplace=True)\n",
        "df_muestra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJ8boy7TSER-"
      },
      "source": [
        "### Género"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCiSG9WXSJyb"
      },
      "outputs": [],
      "source": [
        "# Leer el fichero con los datos de sexo\n",
        "df_gendre = pd.read_csv(f'{data_basepath}sexo_por_comunidad.csv', delimiter=\";\")\n",
        "\n",
        "# Columnas con los pesos\n",
        "gendre_weight_columns = [col for col in df_gendre.columns if col != 'comunidad_autonoma']\n",
        "gendre_weight_columns\n",
        "\n",
        "# Obviamos la columna total de \"ambos sexos\"\n",
        "gendre_weight_columns.remove(\"ambos_sexos\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jtBmugkSN8S"
      },
      "outputs": [],
      "source": [
        "# Generamos la columna categórica \"genero\" con los valores de \"df_gendre\" como pesos\n",
        "df_muestra = include_categorical_values(df_muestra, df_gendre, gendre_weight_columns, \"genero\")\n",
        "\n",
        "# sustituimos los valores de la columna \"genero\" por \"hombre\" y \"mujer\" en singular\n",
        "df_muestra.replace({'genero': {'hombres': 'hombre', 'mujeres': 'mujer'}}, inplace=True)\n",
        "df_muestra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJGS8iYaQbGW"
      },
      "source": [
        "### Actividad física de la población\n",
        "\n",
        "La actividad física de la población se desglosa en `nivel_alto`, `nivel_moderado` y `nivel_bajo`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_0WnjiWQdgA"
      },
      "outputs": [],
      "source": [
        "# Leer el fichero con los datos de la actividad fisica\n",
        "df_activity = pd.read_csv(f'{data_basepath}actividadFisica_por_comunidad.csv', delimiter=\";\")\n",
        "\n",
        "# Columnas con los pesos\n",
        "activity_weight_columns = [col for col in df_activity.columns if col != 'comunidad_autonoma']\n",
        "activity_weight_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Df3aJzc3QyFJ"
      },
      "outputs": [],
      "source": [
        "# Generamos la columna categórica \"actividad_fisica\" con los valores de \"df_activity\" como pesos\n",
        "df_muestra = include_categorical_values(df_muestra, df_activity, activity_weight_columns, \"actividad_fisica\")\n",
        "df_muestra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhSJ6akLTLAj"
      },
      "source": [
        "### Asistencia a eventos\n",
        "\n",
        "La asistencia a eventos incluye varios tipos de eventos, por lo que se discriminará entre cada uno de los tipos para separar los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GbxP8kPTOtC"
      },
      "outputs": [],
      "source": [
        "# Leer el fichero con los datos de la asistencia a eventos\n",
        "df_events = pd.read_csv(f'{data_basepath}asistenciaAEventos_por_comunidad.csv', delimiter=\";\")\n",
        "\n",
        "# Columnas con los pesos\n",
        "events_weight_columns = [col for col in df_events.columns if col != 'comunidad_autonoma']\n",
        "events_weight_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWGcug14TgUA"
      },
      "outputs": [],
      "source": [
        "# Se separarán en varias columnas dependiendo del tipo de evento al que si/no/nopuede asistir (cine, directos, culturales y deportivos)\n",
        "cine_columns = ['cine_si', 'cine_no_puede', 'cine_no']\n",
        "directs_columns = ['directos_si', 'directos_no_puede', 'directos_no']\n",
        "culturals_columns = ['culturales_si', 'culturales_no_puede', 'culturales_no']\n",
        "sports_columns = ['deportivos_si', 'deportivos_no_puede', 'deportivos_no']\n",
        "\n",
        "# Generamos las columnas categóricas \"asistencia_---\" con los valores de \"df_events\" como pesos\n",
        "df_muestra = include_categorical_values(df_muestra, df_events, cine_columns, \"asistencia_cine\")\n",
        "df_muestra = include_categorical_values(df_muestra, df_events, directs_columns, \"asistencia_directos\")\n",
        "df_muestra = include_categorical_values(df_muestra, df_events, culturals_columns, \"asistencia_cultural\")\n",
        "df_muestra = include_categorical_values(df_muestra, df_events, sports_columns, \"asistencia_deporte\")\n",
        "df_muestra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sustituimos los valores de cada columna cine, directos, culturales y deportivos por \"si\", \"no_puede\" y \"no\"\n",
        "df_muestra.replace({'asistencia_cine': {'cine_si': 'si', 'cine_no_puede': 'no_puede', 'cine_no': 'no'}}, inplace=True)\n",
        "df_muestra.replace({'asistencia_directos': {'directos_si': 'si', 'directos_no_puede': 'no_puede', 'directos_no': 'no'}}, inplace=True)\n",
        "df_muestra.replace({'asistencia_cultural': {'culturales_si': 'si', 'culturales_no_puede': 'no_puede', 'culturales_no': 'no'}}, inplace=True)\n",
        "df_muestra.replace({'asistencia_deporte': {'deportivos_si': 'si', 'deportivos_no_puede': 'no_puede', 'deportivos_no': 'no'}}, inplace=True)\n",
        "df_muestra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aeJo8B6TFRf"
      },
      "source": [
        "### Calidad del aire\n",
        "\n",
        "En los datos se muestra la calidad del aire como la media ponderada con la población del número de días al año en que se supera la concentración límite diaria de PM10 por comunidades autónomas (número de días)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xk-LFz9TTxp4"
      },
      "outputs": [],
      "source": [
        "# Leer el fichero con los datos de la calidad de aire\n",
        "df_air_quality = pd.read_csv(f'{data_basepath}calidadDelAire_por_comunidad.csv', delimiter=\";\")\n",
        "df_air_quality.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVRTtGiiUQCR"
      },
      "outputs": [],
      "source": [
        "# Generación de los datos de calidad de aire\n",
        "generate_numerical_column(df_muestra, df_air_quality, \"dias_alta_contaminacion\", \"dias_alta_contaminacion\")\n",
        "df_muestra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUx7a6SMVHyB"
      },
      "source": [
        "### Homicidios y Criminalidad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BLTmwIUVMGv"
      },
      "outputs": [],
      "source": [
        "# Leer el fichero con los datos de homicidios y criminalidad\n",
        "df_criminality = pd.read_csv(f'{data_basepath}criminalidad_por_comunidad.csv', delimiter=\";\")\n",
        "df_criminality.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYmUJjZLVO-L"
      },
      "outputs": [],
      "source": [
        "# Generación de los datos de homicidios por cada 100.000 habitantes\n",
        "generate_numerical_column(df_muestra, df_criminality, \"homicidios_100mhabit\", \"homicidios_por_100mhabit\")\n",
        "df_muestra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AvrZOXrVnAG"
      },
      "outputs": [],
      "source": [
        "# Generación de los datos de criminalidad por cada 1.000 habitantes\n",
        "generate_numerical_column(df_muestra, df_criminality, \"criminalidad_1000habit\", \"criminalidad_por_1000habit\")\n",
        "df_muestra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDhvjlVmY_21"
      },
      "source": [
        "### Nivel educativo\n",
        "\n",
        "Los niveles educativos se reparten entre `analfabetos`, `estudios_primarios_incompletos`, `primaria`, `primero_secundaria`, `segundo_secundaria_general`, `segundo_secundaria_profesional_`, `educacion_superior`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsQu63wxZYB7"
      },
      "outputs": [],
      "source": [
        "# Leer el fichero con los datos de la nivel educativo\n",
        "df_studies = pd.read_csv(f'{data_basepath}educacion_por_comunidad.csv', delimiter=\";\")\n",
        "\n",
        "# Columnas con los pesos (obviando la columna 'total')\n",
        "studies_weight_columns = [col for col in df_studies.columns if col != 'comunidad_autonoma' and col != 'total']\n",
        "studies_weight_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwuZzZ_cZ6iN"
      },
      "outputs": [],
      "source": [
        "df_muestra = include_categorical_values(df_muestra, df_studies, studies_weight_columns, \"estudios\")\n",
        "df_muestra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbZ_keKGbnvq"
      },
      "source": [
        "### Estado civil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsU2wuCNbqtv"
      },
      "outputs": [],
      "source": [
        "# Leer el fichero con los datos del estado civil\n",
        "df_marital_status = pd.read_csv(f'{data_basepath}estadoCivil_por_comunidad.csv', delimiter=\";\")\n",
        "\n",
        "# Columnas con los pesos (obviando la columna 'total')\n",
        "marital_status_weight_columns = [col for col in df_marital_status.columns if col != 'comunidad_autonoma' and col != 'total']\n",
        "marital_status_weight_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ThpNidccHNo"
      },
      "outputs": [],
      "source": [
        "df_muestra = include_categorical_values(df_muestra, df_marital_status, marital_status_weight_columns, \"estado_civil\")\n",
        "df_muestra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAr4d2VxWjiF"
      },
      "source": [
        "### Horas trabajadas\n",
        "\n",
        "Se incluye las horas trabajadas al mes por comunidad, calculando la media de los datos periódicos del año 2024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2qLLS5CW_E8"
      },
      "outputs": [],
      "source": [
        "# Leer el fichero con los datos de las horas trabajadas\n",
        "df_work = pd.read_csv(f'{data_basepath}horasTrabajadasMes_por_comunidad.csv', delimiter=\";\")\n",
        "df_work.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTwRQJnmXETb"
      },
      "outputs": [],
      "source": [
        "# Cálculo de la media de los cuatro períodos\n",
        "# df_work['media_2024'] = df_work.mean(axis=1)\n",
        "df_work['media_2024'] = df_work[['2024T1', '2024T2', '2024T3', '2024T4']].mean(axis=1)\n",
        "\n",
        "# Generación de los datos de salario\n",
        "generate_numerical_column(df_muestra, df_work, \"horasTrabajadas_mes\", \"media_2024\")\n",
        "\n",
        "df_muestra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm8xZ9DEAUOb"
      },
      "source": [
        "### Salario anual\n",
        "\n",
        "Se disponen de las medias de los salarios anuales medios de las comunidades autónomas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ox1Gt-64Am1K"
      },
      "outputs": [],
      "source": [
        "# Leer el fichero con los datos del salario anual\n",
        "df_salary = pd.read_csv(f'{data_basepath}salario_bruto_anual_por_comunidad.csv', delimiter=\";\")\n",
        "df_salary.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cm8KE-h2Atub"
      },
      "outputs": [],
      "source": [
        "# Generación de los datos de salario\n",
        "generate_numerical_column(df_muestra, df_salary, \"salario_anual\", \"ambos_sexos\")\n",
        "df_muestra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x51MUI1jX5QX"
      },
      "source": [
        "### Satisfacción con el sistema sanitario\n",
        "\n",
        "Se han recopilado datos del nivel de satisfacción entre varios servicios sanitarios:\n",
        "\n",
        "* Hospitales\n",
        "* Dentistas\n",
        "* Especialistas\n",
        "* Medicina General\n",
        "\n",
        "Las valoraciones, ordenadas de mejor valorado a menor, varían entre:\n",
        "\n",
        "> `Muy Satisfecho` > `Satisfecho` > `Neutral` > `Insatisfecho` > `Muy Insatisfecho`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vCyhmOYY93_"
      },
      "outputs": [],
      "source": [
        "# Leer el fichero con los datos de la calidad sanitaria\n",
        "df_health = pd.read_csv(f'{data_basepath}satisfaccionSanidad_por_comunidad.csv', delimiter=\";\")\n",
        "\n",
        "# Columnas con los pesos\n",
        "health_columns = [col for col in df_health.columns if col != 'comunidad_autonoma']\n",
        "health_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQRAKJbWZQoM"
      },
      "outputs": [],
      "source": [
        "# Se separarán en varias columnas dependiendo del tipo de atención a valorar (hospital, dentista, especialista y medicina general)\n",
        "hospitals_columns = [\"hospitales_muy_satisfecho/a\", \"hospitales_satisfecho/a\", \"hospitales_neutral\", \"hospitales_insatisfecho/a\", \"hospitales_muy_insatisfecho/a\"]\n",
        "dentist_columns = [\"dentistas_muy_satisfecho/a\", \"dentistas_satisfecho/a\", \"dentistas_neutral\", \"dentistas_insatisfecho/a\", \"dentistas_muy_insatisfecho/a\"]\n",
        "especialist_columns = [\"especialistas_muy_satisfecho/a\", \"especialistas_satisfecho/a\", \"especialistas_neutral\", \"especialistas_insatisfecho/a\", \"especialistas_muy_insatisfecho/a\"]\n",
        "genMed_columns = [\"medGeneral_muy_satisfecho/a\", \"medGeneral_satisfecho/a\", \"medGeneral_neutral\", \"medGeneral_insatisfecho/a\", \"medGeneral_muy_insatisfecho/a\"]\n",
        "\n",
        "# Generamos las columnas categóricas \"asistencia_---\" con los valores de \"df_events\" como pesos\n",
        "df_muestra = include_categorical_values(df_muestra, df_health, hospitals_columns, \"satisf_hospitales\")\n",
        "df_muestra = include_categorical_values(df_muestra, df_health, dentist_columns, \"satisf_dentistas\")\n",
        "df_muestra = include_categorical_values(df_muestra, df_health, especialist_columns, \"satisf_especialistas\")\n",
        "df_muestra = include_categorical_values(df_muestra, df_health, genMed_columns, \"satisf_medGeneral\")\n",
        "df_muestra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7uLJxrO6BzY"
      },
      "source": [
        "## Guardado de fichero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zw9106d5SlU"
      },
      "outputs": [],
      "source": [
        "# prompt: guarda un dataframe en un archivo csv, en la ruta basepath, con el nombre \"datos_tratados.csv\"\n",
        "\n",
        "# Definir la ruta completa del archivo CSV\n",
        "filename = 'datos_tratados.csv'\n",
        "file_path = f'{data_basepath}..\\\\spain_dataframes\\\\{filename}'\n",
        "\n",
        "# Guardar el DataFrame en un archivo CSV\n",
        "df_muestra.to_csv(file_path, index=False)\n",
        "\n",
        "print(f\"DataFrame guardado exitosamente en '{filename}'\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "c54W174ty9ZZ",
        "oMITQ-3OzIzk",
        "H20MVyxRzS-1",
        "n2M5hhRBKMyt",
        "bJ8boy7TSER-",
        "wJGS8iYaQbGW",
        "RhSJ6akLTLAj",
        "9aeJo8B6TFRf",
        "TUx7a6SMVHyB",
        "cDhvjlVmY_21",
        "IbZ_keKGbnvq",
        "hAr4d2VxWjiF",
        "fm8xZ9DEAUOb",
        "x51MUI1jX5QX"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "bootcampIA_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
